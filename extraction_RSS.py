#!/usr/bin/python# -*- coding: utf-8 -*-import RSSParserimport NameExtractorimport codecsdict_names = {}  #uesd for stocking the named entity and propagate itself to each document to treatnbr_words_total = 0articles = RSSParser.rssParse()# treat every article found from the RSSfor article in articles.keys():    print "Extraction of the article : %s"%article    names,nbr_words = NameExtractor.name_extraction(articles[article],dict_names.keys())    for name in names.keys():        if dict_names.has_key(name):            dict_names[name]["name_occurence"] += names[name]            dict_names[name]["doc_frequency"] += 1        else:            dict_names[name] = {                                "name_occurence": 1,                                "doc_frequency": 1}print "%d articles have been treated."%len(articles.keys())print "%d named entity have been found."%len(dict_names.keys())# record the result on a txt filefile = open("result_RSS.txt","w",0)for name in dict_names.keys():    file.write(name)    file.write(" : shows %d times in %d documents.\n"%(dict_names[name]["name_occurence"],dict_names[name]["doc_frequency"]))   file.close()            