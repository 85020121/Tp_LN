#!/usr/bin/python# -*- coding: utf-8 -*-import reimport nltkfrom nltk.tokenize.regexp import RegexpTokenizer########################################## Global Constant ############################################ Proposition de liste non exhaustive de mots pour les rôles grammaticaux# déterminants, pronoms, conjonctions et prépositionsdico = {    # ARTICLES / DETERMINANTS    "DET": ["le", "la", "les", "l'", "un", "une", "des", "d'",        "du", "de", "au", "aux", "ce", "c'", "cet", "cette", "ces",        "mon", "son", "ma", "ta", "sa", "mes", "ses",        "notre", "votre", "leur", "nos", "vos", "leurs",        "aucun", "aucune", "aucuns",         "tel", "telle", "tels", "telles",        "tout", "toute", "tous", "toutes",        "chaque"],    # PRONOM    "PRO": ["je", "j'", "tu", "il", "elle", "on", "nous", "vous", "ils", "elles",        "me", "m'", "moi", "te", "t'", "toi", "cela", "celui", "celles", "ceux",        "se", "y", "le", "lui", "soi", "leur", "eux", "lui",        "qui", "que", "quoi", "dont" "où"],    # CONJONCTION    "CONJ": ["mais", "ou", "et", "donc", "or", "ni", "car",        "que", "qu", "quand", "comme", "si", "s'", "dont",        "lorsque", "quoique", "puisque", "pourquoi"],    # PREPOSITION    "PREP": ["à", "derrière", "malgré", "sauf", "chez", "concernant", "contre", "dès",        "selon", "avant", "devant", "sous", "avec", "durant", "hormis", "hors",        "en", "par", "sur", "entre", "parmi", "jusque", "jusqu'", "malgré", "moyennant", "nonobstant",        "envers", "pendant", "vers", "dans", "pour", "de", "d'", "outre", "parmi", "suaf", "selon",        "près", "depuis", "sans","après", "suivant", "touchant", "via", "voilà", "voici"],    # AUTRE    "AUTRE": ["non", "oui", "alors", "messieurs", "mesdames", "français", "république", "le président", "ministre",              "premier", "deuxième", "toutefois", "parfois", "quelque", "quelques", "ainsi", "duex", "trois", "presque", "presqu'", "lors",              "lundi", "mardi", "mercredi", "jeudi", "vendredi", "samedi", "dimanche",              "janvier", "février", "mars", "avril", "mai", "juin", "juillet", "août", "septembre", "octobre", "novembre", "décembre",                            "homme", "femme", "humain", "comment", "quand", "quel", "quelle", "plus", "moins", "monde"]}reg_words = r'''(?x)          aujourd'hui    # exception 1        | prud'hom\w+ # exception 2        | \d+(,\d+)?\s*[%€$] # les valeurs        | \d+                # les nombres        | \w'                 # les contractions d', l', j', t', s'        | \w+(-\w+)+    # les mots composés        | (\d|\w)+         # les combinaisons alphanumériques        | \w+               # les mots simples        '''tokenizer = RegexpTokenizer(reg_words, flags=re.UNICODE|re.IGNORECASE)def inDico(word):    return dico.get("DET").__contains__(word) or dico.get("PRO").__contains__(word) or dico.get("CONJ").__contains__(word)  or dico.get("PREP").__contains__(word)or dico.get("AUTRE").__contains__(word)# M. Sqrkozy | M. Nicolas Sarkozy | Monsieur Charle de Gaule, etcregexp_1 = re.compile(r"((M\.|Mme|Mlle|Monsieur|Madame|Mademoiselle)\s)(\b[A-Z][A-Za-zéàçè]+)(([\s|\-]\b[A-Z][A-Za-zéàçè]+\b)*)", re.U)# stock the names which are accompanied by a title of civilityintsant_names = set()# add the name which is accompanied by a title of civility to the dictionary instantdef regle_1(text):    for n in regexp_1.finditer(text):        name=n.group(3)        if n.group(4)!=None:            name+=n.group(4)        intsant_names.add(name)        # composition of the name ==> \b[A-Z][A-Za-zéàçè]+\b     regexp_2 = re.compile(r"((M\.|Mme|Mlle|Monsieur|Madame|Mademoiselle)\s)?(\b[A-Z][A-Za-zéàçè]+\b)(([\s|\-](de\s)?(d')?\b[A-Z][A-Za-zéàçè]+\b)*)", re.U)# extraction of the proper nouns with expreg# @param sent: sentence to traiter # @param names: dictionaire de names# effet: add the name into the dictionary if found def regle_2(s,names):    for n in regexp_2.finditer(s):        name = n.group(3)        if inDico(name.lower()):            name = ""        if n.group(4)!=None:            name+=n.group(4)        if name == "":            return        if names.has_key(name):            names[name] += 1        else:            names[name] = 1    # verify if the first word of the sentence is a proper noun# @param sent: sentence to treat# @param text: text # @param names: dictionary of names# @return True if the first word of the sentence is a proper noun, False if not  def rule_firstWord(sent,text,names):    words = tokenizer.tokenize(sent)    if not len(words)>1:        return False    first = words[0]    if intsant_names.__contains__(first):        return True    first = first.lower()    if text.find(first) != -1:        return False    if inDico(first):        return False    if not words[1].islower() and words[1].isalpha():        return True    clean_word = first    try:        clean_word,rest = first.split("-",1)    except ValueError:         e = ""    if inDico(clean_word):        return False    if clean_word.endswith("ment") or clean_word.endswith("ez"):        return False    return False    # fonction principal# @param text: text to treat# @param dict_names: dictionary de names# @return dictionary of names updated   def name_extraction(text,dict_names):    nbr_word = len(tokenizer.tokenize(text))    regle_1(text)    intsant_names.union(dict_names)    names = {}    for s in nltk.sent_tokenize(text):        if len(s.split()) >1:            if rule_firstWord(s, text, names):                regle_2(s, names)            else:                try:                    first, rest = s.split(" ", 1)                    regle_2(rest, names)                except ValueError:                     e = ""       return names,nbr_word    