#!/usr/bin/python# -*- coding: utf-8 -*-import reimport nltkfrom nltk.tokenize.regexp import RegexpTokenizer########################################## Global Constant ############################################ Proposition de liste non exhaustive de mots pour les rôles grammaticaux# déterminants, pronoms, conjonctions et prépositionsdico = {    # ARTICLES / DETERMINANTS    "DET": ["le", "la", "les", "l'", "un", "une", "des", "d'",        "du", "de", "au", "aux", "ce", "c'", "cet", "cette", "ces",        "mon", "son", "ma", "ta", "sa", "mes", "ses",        "notre", "votre", "leur", "nos", "vos", "leurs",        "aucun", "aucune", "aucuns",         "tel", "telle", "tels", "telles",        "tout", "toute", "tous", "toutes",        "chaque"],    # PRONOM    "PRO": ["je", "j'", "tu", "il", "elle", "on", "nous", "vous", "ils", "elles",        "me", "m'", "moi", "te", "t'", "toi",        "se", "y", "le", "lui", "soi", "leur", "eux", "lui",        "qui", "que", "quoi", "dont" "où"],    # CONJONCTION    "CONJ": ["mais", "ou", "et", "donc", "or", "ni", "car",        "que", "qu", "quand", "comme", "si", "s'", "dont",        "lorsque", "quoique", "puisque", "pourquoi"],    # PREPOSITION    "PREP": ["à", "derrière", "malgré", "sauf", "chez", "concernant", "contre", "dès",        "selon", "avant", "devant", "sous", "avec", "durant", "hormis", "hors",        "en", "par", "sur", "entre", "parmi", "jusque", "jusqu'", "malgré", "moyennant", "nonobstant",        "envers", "pendant", "vers", "dans", "pour", "de", "d'", "outre", "parmi", "suaf", "selon",        "près", "depuis", "sans","après", "suivant", "touchant", "via", "voilà", "voici"],    # AUTRE    "AUTRE": ["non", "oui", "alors", "messieurs", "mesdames", "français", "république", "le président", "ministre",              "premier", "deuxième", "toutefois", "parfois", "quelque", "duex", "trois", "presque", "presqu'",              "lundi", "mardi", "mercredi", "jeudi", "vendredi", "samedi", "dimanche",              "janvier", "février", "mars", "avril", "mai", "juin", "juillet", "août", "septembre", "octobre", "novembre", "décembre",                            "homme", "femme", "humain", "comment", "quand", "quel", "quelle", "plus", "moins", "monde"]}reg_words = r'''(?x)          aujourd'hui    # exception 1        | prud'hom\w+ # exception 2        | \d+(,\d+)?\s*[%€$] # les valeurs        | \d+                # les nombres        | \w'                 # les contractions d', l', j', t', s'        | \w+(-\w+)+    # les mots composés        | (\d|\w)+         # les combinaisons alphanumériques        | \w+               # les mots simples        '''tokenizer = RegexpTokenizer(reg_words, flags=re.UNICODE|re.IGNORECASE)def inDico(word):    return dico.get("DET").__contains__(word) or dico.get("PRO").__contains__(word) or dico.get("CONJ").__contains__(word)  or dico.get("PREP").__contains__(word)or dico.get("AUTRE").__contains__(word)# reconnaitre M. Sqrkozy | M. Nicolas Sarkozy | Monsieur Charle de Gaule, etcregexp_1 = re.compile(r"((M\.|Mme|Mlle|Monsieur|Madame|Mademoiselle)\s)(\b[A-Z][A-Za-zéàçè]+)(([\s|\-]\b[A-Z][A-Za-zéàçè]+\b)*)", re.U)# enregistrer les nomsintsant_names = set()# ajouter le nom qui est accompagné avec un titre de civilité dans le dictionaire instantdef regle_1(text):    for n in regexp_1.finditer(text):        name=n.group(3)        if n.group(4)!=None:            name+=n.group(4)        intsant_names.add(name)        # composition d'un nom ==> \b[A-Z][A-Za-zéàçè]+\b     regexp_2 = re.compile(r"((M\.|Mme|Mlle|Monsieur|Madame|Mademoiselle)\s)?(\b[A-Z][A-Za-zéàçè]+\b)(([\s|\-](de\s)?(d')?\b[A-Z][A-Za-zéàçè]+\b)*)", re.U)#regexp_3 = re.compile(r"^[A-Z][A-Za-zéàçè]+(\s\b[A-ZÇÉÈÖÔÛ][A-Za-zéàçè]+\b)+", re.U)# extraction des noms propres en appliquant l'expreg# @sent prashe à traiter # @names dictionaire de noms# effet ajouter le nom dans dictionaire si l'on a tourvédef regle_2(s,names):    for n in regexp_2.finditer(s):        name = n.group(3)        if inDico(name.lower()):            name = ""        if n.group(4)!=None:            name+=n.group(4)        if name == "":            return        if names.has_key(name):            names[name] += 1        else:            names[name] = 1    # vérifier si le premier mot du prashe est un nom propre# @sent prashe à traiter# @text text # @names dictionaire de noms# return vrai si le premier mot est un nom propre, faux sinon  def rule_firstWord(sent,text,names):    words = tokenizer.tokenize(sent)    if not len(words)>1:        return False    first = words[0]    if intsant_names.__contains__(first):        return True    first = first.lower()    if text.find(first) != -1:        return False    if inDico(first):        return False    if not words[1].islower() and words[1].isalpha():        return True    clean_word = first    try:        clean_word,rest = first.split("-",1)    except ValueError:         e = ""    if inDico(clean_word):        return False    if clean_word.endswith("ment") or clean_word.endswith("ez"):        return False    names["ambigu"].add(words[0])    return False    # fonction principale# @text text à traiter# @dict_names dictionaire de noms# return dictionaire de noms updated   def name_extraction(text,dict_names):    regle_1(text)    for s in nltk.sent_tokenize(text):        if len(s.split()) >1:            if rule_firstWord(s, text, dict_names):                regle_2(s, dict_names)            else:                try:                    first, rest = s.split(" ", 1)                    regle_2(rest, dict_names)                except ValueError:                     e = ""       return dict_names    